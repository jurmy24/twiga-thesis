{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study Calculations\n",
    "This notebook contains all my code to run the ablation study and to compute the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATA_DIR = os.getenv(\"DATA_DIR_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd() # Get the current working directory of the notebook\n",
    "src_dir = os.path.abspath(os.path.join(notebook_dir, '..', '..')) # Construct the path to the src directory\n",
    "sys.path.append(src_dir) # Add the src directory to the system path\n",
    "\n",
    "from src.prompt_templates import PIPELINE_QUESTION_GENERATOR_PROMPT_ZERO_SHOT, PIPELINE_QUESTION_GENERATOR_USER_PROMPT\n",
    "from src.pipelines.pipeline_runner import run_data_through_generator\n",
    "from src.utils import load_json_to_pipelinedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a skilled Tanzanian secondary school teacher that generates questions or exercises for Tanzanian Form 2 geography students based on the request made by the user. \n",
      "Use your the provided context from the textbook to ensure that the questions you generate are grounded in the course content.\n",
      "Given the context information and not prior knowledge, follow the query instructions provided by the user. Begin your response immediately with the question.\n",
      "Follow these instructions ({query})\n",
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_file = os.path.join(DATA_DIR, \"datasets\", \"ablation\", \"test-prompts-rewritten-retrieved.json\")\n",
    "output_file = os.path.join(DATA_DIR, \"results\", \"7-pipeline-llama3.json\")\n",
    "\n",
    "with open(input_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "incomplete_pipeline_data = load_json_to_pipelinedata(data)\n",
    "\n",
    "res = run_data_through_generator(incomplete_pipeline_data, \"llama3-70b-8192\", verbose=False)\n",
    "\n",
    "save_objects_as_json(res, output_file, rewrite=True)\n",
    "\n",
    "print(PIPELINE_QUESTION_GENERATOR_PROMPT_ZERO_SHOT)\n",
    "print(PIPELINE_QUESTION_GENERATOR_USER_PROMPT)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
