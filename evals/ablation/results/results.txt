CONTROL-query-rewriter Hit Rate: 0.03333333333333333
CONTROL-query-rewriter MRR: 0.03333333333333333
MAIN-query-rewriter Hit Rate: 0.96 (WITH GPT-4o)
MAIN-query-rewriter MRR: 0.8967777777777779 (with GPT-4o)
CONTROL-query-rewriter BERTscore Precision: 0.42478466033935547, Recall: 0.4540499448776245, F1: 0.43694067001342773
MAIN-query-rewriter BERTscore Precision: 0.42856526374816895, Recall: 0.5334873199462891, F1: 0.4725988209247589
CONTROL-query-rewriter all-MiniLM-l6-v2 Cosine Similarity: 0.26755961019548874
MAIN-query-rewriter all-MiniLM-l6-v2 Cosine Similarity: 0.5571065216789489
CONTROL-query-rewriter K-F1++: 0.19016749935263574, Precision: 0.3226106219744541 Recall: 0.17658751821458243
MAIN-query-rewriter K-F1++: 0.21061371369957022, Precision: 0.5912144573892666 Recall: 0.16385168271477207
CONTROL-query-rewriter Hit Rate: 0.0
CONTROL-query-rewriter MRR: 0.0
MAIN-query-rewriter Hit Rate: 0.91
MAIN-query-rewriter MRR: 0.8411666666666667
CONTROL-sparse-retriever Hit Rate: 0.0
CONTROL-sparse-retriever MRR: 0.0
MAIN-sparse-retriever Hit Rate: 0.8666666666666667
MAIN-sparse-retriever MRR: 0.8208333333333335
CONTROL-sparse-retriever BERTscore Precision: 0.4237977862358093, Recall: 0.46290621161460876, F1: 0.44082608819007874
MAIN-sparse-retriever BERTscore Precision: 0.43512019515037537, Recall: 0.5416387915611267, F1: 0.47999393939971924
CONTROL-sparse-retriever all-MiniLM-l6-v2 Cosine Similarity: 0.28185347755637236
MAIN-sparse-retriever all-MiniLM-l6-v2 Cosine Similarity: 0.5872356174372269
CONTROL-sparse-retriever K-F1++: 0.1900649228955347, Precision: 0.35406089193861806 Recall: 0.15289190713488807
MAIN-sparse-retriever K-F1++: 0.21316623991461933, Precision: 0.5914073294777338 Recall: 0.15693280260474723
CONTROL-reranker Hit Rate: 0.0
CONTROL-reranker MRR: 0.0
MAIN-reranker Hit Rate: 0.8766666666666667
MAIN-reranker MRR: 0.817888888888889
CONTROL-reranker BERTscore Precision: 0.42336347699165344, Recall: 0.4518900513648987, F1: 0.4353734850883484
MAIN-reranker BERTscore Precision: 0.4295743405818939, Recall: 0.5393234491348267, F1: 0.4755952060222626
CONTROL-reranker all-MiniLM-l6-v2 Cosine Similarity: 0.2230403546657391
MAIN-reranker all-MiniLM-l6-v2 Cosine Similarity: 0.566966996352292
CONTROL-reranker K-F1++: 0.2248227434159746, Precision: 0.3372607791564718 Recall: 0.18581041140823895
MAIN-reranker K-F1++: 0.20174380930655728, Precision: 0.6107602168265688 Recall: 0.13935757021067857
CONTROL-sample-questions BERTscore Precision: 0.42377179861068726, Recall: 0.45648473501205444, F1: 0.43822649121284485
MAIN-sample-questions BERTscore Precision: 0.4346897304058075, Recall: 0.5416320562362671, F1: 0.4798716604709625
CONTROL-sample-questions all-MiniLM-l6-v2 Cosine Similarity: 0.23363185697936917
MAIN-sample-questions all-MiniLM-l6-v2 Cosine Similarity: 0.5854144835777617
CONTROL-sample-questions K-F1++: 0.17221193861250844, Precision: 0.2933320137384273 Recall: 0.13822915598445046
MAIN-sample-questions K-F1++: 0.21163101955962907, Precision: 0.5910358209413619 Recall: 0.15701541773068065
CONTROL-one-shot BERTscore Precision: 0.4286099672317505, Recall: 0.45384612679481506, F1: 0.43992456793785095
MAIN-one-shot BERTscore Precision: 0.47350195050239563, Recall: 0.5182095170021057, F1: 0.4925309717655182
CONTROL-one-shot all-MiniLM-l6-v2 Cosine Similarity: 0.2734614029036394
MAIN-one-shot all-MiniLM-l6-v2 Cosine Similarity: 0.5756420818552409
CONTROL-one-shot K-F1++: 0.2307450186952547, Precision: 0.40762866390238817 Recall: 0.18284604216230355
MAIN-one-shot K-F1++: 0.2532638809058312, Precision: 0.5004349402217616 Recall: 0.21045668107756266
CONTROL-query-rewriter RAGAS Groundedness: 0.31666666666666665, Answer Relevancy: 0.4286652754806194, Context Relevancy: 0.011580459770114942, Reverse Context Relevancy: 0.0027872058104616245
MAIN-query-rewriter RAGAS Groundedness: 0.8471666666666667, Answer Relevancy: 0.8728375054401637, Context Relevancy: 0.11329539735201212, Reverse Context Relevancy: 0.13241960811999495
CONTROL-sparse-retriever RAGAS Groundedness: 0.3333333333333333, Answer Relevancy: 0.4235005477572738, Context Relevancy: 0.01229469398766386, Reverse Context Relevancy: 0.039640588833558706
MAIN-sparse-retriever RAGAS Groundedness: 0.8188333333333333, Answer Relevancy: 0.873045599261869, Context Relevancy: 0.13572042250380087, Reverse Context Relevancy: 0.1173593364138298
CONTROL-reranker RAGAS Groundedness: 0.3433333333333334, Answer Relevancy: 0.42166765267602135, Context Relevancy: 0.0024857201142390864, Reverse Context Relevancy: 0.009588466891928446
MAIN-reranker RAGAS Groundedness: 0.8151666666666667, Answer Relevancy: 0.8692538426363156, Context Relevancy: 0.12252496979246147, Reverse Context Relevancy: 0.10191665272680049
CONTROL-sample-questions RAGAS Groundedness: 0.25277777777777777, Answer Relevancy: 0.37556081222990495, Reverse Context Relevancy: 0.002874149659863946
MAIN-sample-questions RAGAS Groundedness: 0.8242002442002443, Answer Relevancy: 0.8631171918196182, Reverse Context Relevancy: 0.12051018228845362
CONTROL-one-shot RAGAS Groundedness: 0.6216666666666667, Answer Relevancy: 0.7315426290481462, Reverse Context Relevancy: 0.025067177294610242
MAIN-one-shot RAGAS Groundedness: 0.8542142857142858, Answer Relevancy: 0.8608795502667829, Reverse Context Relevancy: 0.14084267141884743
