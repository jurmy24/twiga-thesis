{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute MDG survey results\n",
    "\n",
    "This document will allow us to compute the MDG averages from the users and Krippendorf's alpha between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "csv_mdg_1_path = \"../../evals/human/multi-dimension/results/twiga-mdg-1.csv\"\n",
    "csv_mdg_2_path = \"../../evals/human/multi-dimension/results/twiga-mdg-2.csv\"\n",
    "csv_mdg_3_path = \"../../evals/human/multi-dimension/results/twiga-mdg-3.csv\"\n",
    "json_mdg_path = \"../../evals/human/multi-dimension/multi-dimension-survey.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the question list to a DataFrame per questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read JSON file of queries into three separate mdg survey dataframes\"\"\"\n",
    "with open(json_mdg_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the relevant information and store it in a dictionary\n",
    "mdg_queries_1_df = pd.DataFrame(data[0:12])\n",
    "mdg_queries_2_df = pd.DataFrame(data[12:24])\n",
    "mdg_queries_3_df = pd.DataFrame(data[24:36])\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    print(mdg_queries_1_df.columns)\n",
    "    print(mdg_queries_2_df.columns)\n",
    "    print(mdg_queries_3_df.columns)\n",
    "\n",
    "    print(len(mdg_queries_1_df))\n",
    "    print(len(mdg_queries_2_df))\n",
    "    print(len(mdg_queries_3_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the multi-dimension surveys into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame, skipping two unnecessary rows\n",
    "\n",
    "mdg_responses_1_df = pd.read_csv(csv_mdg_1_path, skiprows=[1,2])\n",
    "mdg_responses_2_df = pd.read_csv(csv_mdg_2_path, skiprows=[1,2])\n",
    "mdg_responses_3_df = pd.read_csv(csv_mdg_3_path, skiprows=[1,2])\n",
    "\n",
    "# Assuming the first column is 'Name' and subsequent columns are responses\n",
    "name_column = mdg_responses_2_df.columns[17]  # The title of the name column\n",
    "sanity_check_columns = mdg_responses_2_df.columns[21:30] # TODO: get the actual query-response pair I made manually and show them somewhere along with these (can put in appendix)\n",
    "response_columns = mdg_responses_2_df.columns[30:66] # The titles of the question columns and associated responses\n",
    "\n",
    "def fill_data(mdg_df: pd.DataFrame, num_respondents:int) -> pd.DataFrame:\n",
    "    data_dict = {\n",
    "        \"question_number\": [\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9\",\"Q10\",\"Q11\",\"Q12\",\"Q13\",\"Q14\"]*num_respondents,\n",
    "        \"respondent\": [],\n",
    "        \"answer_relevance\": [],\n",
    "        \"formulation\": [],\n",
    "        \"suitability\": []\n",
    "    }\n",
    "    for _, row in mdg_df.iterrows():\n",
    "        name = row[name_column]\n",
    "        name = uuid.uuid4()\n",
    "        responses = row[response_columns].tolist()\n",
    "        \n",
    "        answer_relevance_responses = responses[::3]\n",
    "        formulation_responses = responses[1::3]\n",
    "        suitability_responses = responses[2::3]\n",
    "        \n",
    "        for ar, fr, sr in zip(answer_relevance_responses, formulation_responses, suitability_responses):\n",
    "            data_dict[\"respondent\"].append(name)\n",
    "            data_dict[\"answer_relevance\"].append(ar)\n",
    "            data_dict[\"formulation\"].append(fr)\n",
    "            data_dict[\"suitability\"].append(sr)\n",
    "    \n",
    "    return pd.DataFrame(data_dict)\n",
    "\n",
    "mdg_1_data_df = fill_data(mdg_responses_1_df, 4)\n",
    "mdg_2_data_df = fill_data(mdg_responses_2_df, 3)\n",
    "mdg_3_data_df = fill_data(mdg_responses_3_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the question description DataFrames and the response data DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First expand the queries DataFrames to be the same length as the response DataFrames\n",
    "mdg_queries_1_df_expanded = pd.concat([mdg_queries_1_df] * 4, ignore_index=True) # note that the first survey has 4 respondents\n",
    "mdg_queries_2_df_expanded = pd.concat([mdg_queries_2_df] * 3, ignore_index=True)\n",
    "mdg_queries_3_df_expanded = pd.concat([mdg_queries_3_df] * 3, ignore_index=True)\n",
    "\n",
    "# Concatenate the DataFrames along the columns\n",
    "mdg_queries_1_complete = pd.concat([mdg_queries_1_df_expanded, mdg_1_data_df], axis=1)\n",
    "mdg_queries_2_complete = pd.concat([mdg_queries_2_df_expanded, mdg_2_data_df], axis=1)\n",
    "mdg_queries_3_complete = pd.concat([mdg_queries_3_df_expanded, mdg_3_data_df], axis=1)\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    print(mdg_queries_1_complete.columns)\n",
    "    print(mdg_queries_2_complete.columns)\n",
    "    print(mdg_queries_3_complete.columns)\n",
    "\n",
    "mdg_queries_1_complete.to_csv(\"../../evals/human/multi-dimension/results/data1.csv\")\n",
    "mdg_queries_2_complete.to_csv(\"../../evals/human/multi-dimension/results/data2.csv\")\n",
    "mdg_queries_3_complete.to_csv(\"../../evals/human/multi-dimension/results/data3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index of questions per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check this directly in the survey\n",
    "mdg_survey_1_index = {\n",
    "    \"baseline-gpt-3-5-turbo-16k-0613\": [8,11],\n",
    "    \"assistant-gpt-3-5-turbo-16k-0613\": [0,1,3,4,5,6,9],\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": [2,7,10],\n",
    "}\n",
    "\n",
    "# Double check this directly in the survey\n",
    "mdg_survey_2_index = {\n",
    "    \"baseline-gpt-3-5-turbo-16k-0613\": [0,3,6,9,11],\n",
    "    \"assistant-gpt-3-5-turbo-16k-0613\": [5,10],\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": [1,2,4,7,8],\n",
    "}\n",
    "\n",
    "# Double check this directly in the survey\n",
    "mdg_survey_3_index = {\n",
    "    \"baseline-gpt-3-5-turbo-16k-0613\": [0,2,5,7,9],\n",
    "    \"assistant-gpt-3-5-turbo-16k-0613\": [1,6,10],\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": [3,4,8,11],\n",
    "}\n",
    "\n",
    "QUESTION_ID_CONVERSION = {\n",
    "    0: \"Q3\",\n",
    "    1: \"Q4\",\n",
    "    2: \"Q5\",\n",
    "    3: \"Q6\",\n",
    "    4: \"Q7\",\n",
    "    5: \"Q8\",\n",
    "    6: \"Q9\",\n",
    "    7: \"Q10\",\n",
    "    8: \"Q11\",\n",
    "    9: \"Q12\",\n",
    "    10: \"Q13\",\n",
    "    11: \"Q14\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the relevant results for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/2088164473.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  baseline_df_1['question_number'] = baseline_df_1['question_number']+\"-survey-1\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/2088164473.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  baseline_df_2['question_number'] = baseline_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/2088164473.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  baseline_df_3['question_number'] = baseline_df_3['question_number']+\"-survey-3\"\n"
     ]
    }
   ],
   "source": [
    "mdg_queries_1_complete = pd.read_csv(\"../../evals/human/multi-dimension/results/data1.csv\")\n",
    "mdg_queries_2_complete = pd.read_csv(\"../../evals/human/multi-dimension/results/data2.csv\")\n",
    "mdg_queries_3_complete = pd.read_csv(\"../../evals/human/multi-dimension/results/data3.csv\")\n",
    "\n",
    "# List of question numbers to match in the respective surveys\n",
    "baseline_match_1 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_1_index[\"baseline-gpt-3-5-turbo-16k-0613\"]]\n",
    "baseline_match_2 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_2_index[\"baseline-gpt-3-5-turbo-16k-0613\"]]\n",
    "baseline_match_3 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_3_index[\"baseline-gpt-3-5-turbo-16k-0613\"]]\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'Name' column matches any name in the list\n",
    "baseline_df_1 = mdg_queries_1_complete[mdg_queries_1_complete['question_number'].isin(baseline_match_1)]\n",
    "baseline_df_2 = mdg_queries_2_complete[mdg_queries_2_complete['question_number'].isin(baseline_match_2)]\n",
    "baseline_df_3 = mdg_queries_3_complete[mdg_queries_3_complete['question_number'].isin(baseline_match_3)]\n",
    "\n",
    "# Update the question_number identifiers\n",
    "baseline_df_1['question_number'] = baseline_df_1['question_number']+\"-survey-1\"\n",
    "baseline_df_2['question_number'] = baseline_df_2['question_number']+\"-survey-2\"\n",
    "baseline_df_3['question_number'] = baseline_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "# baseline_df = pd.concat([baseline_df_1, baseline_df_2, baseline_df_3], axis=0, ignore_index=True)\n",
    "baseline_df = pd.concat([baseline_df_2, baseline_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "baseline_df.to_csv(\"../../evals/human/multi-dimension/results/baseline_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the relevant results for assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/1277704028.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assistant_df_1['question_number'] = assistant_df_1['question_number']+\"-survey-1\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/1277704028.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assistant_df_2['question_number'] = assistant_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/1277704028.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assistant_df_3['question_number'] = assistant_df_3['question_number']+\"-survey-3\"\n"
     ]
    }
   ],
   "source": [
    "# List of question numbers to match in the respective surveys\n",
    "assistant_match_1 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_1_index[\"assistant-gpt-3-5-turbo-16k-0613\"]]\n",
    "assistant_match_2 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_2_index[\"assistant-gpt-3-5-turbo-16k-0613\"]]\n",
    "assistant_match_3 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_3_index[\"assistant-gpt-3-5-turbo-16k-0613\"]]\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'Name' column matches any name in the list\n",
    "assistant_df_1 = mdg_queries_1_complete[mdg_queries_1_complete['question_number'].isin(assistant_match_1)]\n",
    "assistant_df_2 = mdg_queries_2_complete[mdg_queries_2_complete['question_number'].isin(assistant_match_2)]\n",
    "assistant_df_3 = mdg_queries_3_complete[mdg_queries_3_complete['question_number'].isin(assistant_match_3)]\n",
    "\n",
    "# Update the question_number identifiers\n",
    "assistant_df_1['question_number'] = assistant_df_1['question_number']+\"-survey-1\"\n",
    "assistant_df_2['question_number'] = assistant_df_2['question_number']+\"-survey-2\"\n",
    "assistant_df_3['question_number'] = assistant_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "# assistant_df = pd.concat([assistant_df_1, assistant_df_2, assistant_df_3], axis=0, ignore_index=True)\n",
    "assistant_df = pd.concat([assistant_df_2, assistant_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "assistant_df.to_csv(\"../../evals/human/multi-dimension/results/assistant_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the relevant results for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/225373876.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_1['question_number'] = pipeline_df_1['question_number']+\"-survey-1\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/225373876.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_2['question_number'] = pipeline_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/225373876.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_3['question_number'] = pipeline_df_3['question_number']+\"-survey-3\"\n"
     ]
    }
   ],
   "source": [
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[query] for query in mdg_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"]]\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'Name' column matches any name in the list\n",
    "pipeline_df_1 = mdg_queries_1_complete[mdg_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_df_2 = mdg_queries_2_complete[mdg_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "pipeline_df_3 = mdg_queries_3_complete[mdg_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Update the question_number identifiers\n",
    "pipeline_df_1['question_number'] = pipeline_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_df_2['question_number'] = pipeline_df_2['question_number']+\"-survey-2\"\n",
    "pipeline_df_3['question_number'] = pipeline_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "# pipeline_df = pd.concat([pipeline_df_1, pipeline_df_2, pipeline_df_3], axis=0, ignore_index=True)\n",
    "pipeline_df = pd.concat([pipeline_df_2, pipeline_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "pipeline_df.to_csv(\"../../evals/human/multi-dimension/results/pipeline_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get values of interest from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages (0=baseline, 1=assistant, 2=pipeline)\n",
      "   answer_relevance  formulation  suitability\n",
      "0          4.233333     4.466667     4.366667\n",
      "1          4.133333     4.333333     4.333333\n",
      "2          4.222222     4.333333     4.259259\n"
     ]
    }
   ],
   "source": [
    "baseline_results = pd.read_csv(\"../../evals/human/multi-dimension/results/baseline_results.csv\")\n",
    "assistant_results = pd.read_csv(\"../../evals/human/multi-dimension/results/assistant_results.csv\")\n",
    "pipeline_results = pd.read_csv(\"../../evals/human/multi-dimension/results/pipeline_results.csv\")\n",
    "\n",
    "baseline_averages = baseline_results.groupby('source_file')[['answer_relevance', 'formulation', 'suitability']].mean()\n",
    "assistant_averages = assistant_results.groupby('source_file')[['answer_relevance', 'formulation', 'suitability']].mean()\n",
    "pipeline_averages = pipeline_results.groupby('source_file')[['answer_relevance', 'formulation', 'suitability']].mean()\n",
    "\n",
    "# print(len(baseline_averages))\n",
    "# print(assistant_averages.head())\n",
    "# print(pipeline_averages.head())\n",
    "results_df = pd.concat([baseline_averages, assistant_averages, pipeline_averages], axis=0, ignore_index=True)\n",
    "print(\"Averages (0=baseline, 1=assistant, 2=pipeline)\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mean (0=baseline, 1=assistant, 2=pipeline)\n",
      "   answer_relevance  formulation  suitability\n",
      "0          0.170754     0.104313     0.155241\n",
      "1          0.306542     0.270214     0.186871\n",
      "2          0.179691     0.150970     0.156462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/60629283.py:15: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  sem_baseline = baseline_stds / np.sqrt(int(n_respondents_baseline))\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/60629283.py:16: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  sem_assistant = assistant_stds / np.sqrt(int(n_respondents_assistant))\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_5018/60629283.py:17: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  sem_pipeline = pipeline_stds / np.sqrt(int(n_respondents_pipeline))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate standard deviations\n",
    "baseline_stds = baseline_results.groupby('source_file')[['answer_relevance', 'formulation', 'suitability']].std()\n",
    "assistant_stds = assistant_results.groupby('source_file')[['answer_relevance', 'formulation', 'suitability']].std()\n",
    "pipeline_stds = pipeline_results.groupby('source_file')[['answer_relevance', 'formulation', 'suitability']].std()\n",
    "\n",
    "# Number of respondents per pipeline (assuming equal number of responses per pipeline for simplicity)\n",
    "n_respondents_baseline = baseline_results.groupby('source_file').size()\n",
    "n_respondents_assistant = assistant_results.groupby('source_file').size()\n",
    "n_respondents_pipeline = pipeline_results.groupby('source_file').size()\n",
    "\n",
    "\n",
    "# Calculate standard error of the mean (SEM) - \n",
    "sem_baseline = baseline_stds / np.sqrt(int(n_respondents_baseline))\n",
    "sem_assistant = assistant_stds / np.sqrt(int(n_respondents_assistant))\n",
    "sem_pipeline = pipeline_stds / np.sqrt(int(n_respondents_pipeline))\n",
    "\n",
    "standard_errors_df = pd.concat([sem_baseline, sem_assistant, sem_pipeline], axis=0, ignore_index=True)\n",
    "print(\"Standard mean (0=baseline, 1=assistant, 2=pipeline)\")\n",
    "print(standard_errors_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'baseline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (metric, title, color, hatch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(metrics, titles, colors, hatches)):\n\u001b[0;32m---> 63\u001b[0m     means \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     64\u001b[0m     errors \u001b[38;5;241m=\u001b[39m [standard_errors_df\u001b[38;5;241m.\u001b[39mloc[pipeline, metric] \u001b[38;5;28;01mfor\u001b[39;00m pipeline \u001b[38;5;129;01min\u001b[39;00m pipelines]\n\u001b[1;32m     65\u001b[0m     bars \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mbar(positions \u001b[38;5;241m+\u001b[39m offsets[i], means, yerr\u001b[38;5;241m=\u001b[39merrors, capsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, width\u001b[38;5;241m=\u001b[39mbar_width, color\u001b[38;5;241m=\u001b[39mcolor, label\u001b[38;5;241m=\u001b[39mtitle, hatch\u001b[38;5;241m=\u001b[39mhatch)\n",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (metric, title, color, hatch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(metrics, titles, colors, hatches)):\n\u001b[0;32m---> 63\u001b[0m     means \u001b[38;5;241m=\u001b[39m [\u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pipeline \u001b[38;5;129;01min\u001b[39;00m pipelines]\n\u001b[1;32m     64\u001b[0m     errors \u001b[38;5;241m=\u001b[39m [standard_errors_df\u001b[38;5;241m.\u001b[39mloc[pipeline, metric] \u001b[38;5;28;01mfor\u001b[39;00m pipeline \u001b[38;5;129;01min\u001b[39;00m pipelines]\n\u001b[1;32m     65\u001b[0m     bars \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mbar(positions \u001b[38;5;241m+\u001b[39m offsets[i], means, yerr\u001b[38;5;241m=\u001b[39merrors, capsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, width\u001b[38;5;241m=\u001b[39mbar_width, color\u001b[38;5;241m=\u001b[39mcolor, label\u001b[38;5;241m=\u001b[39mtitle, hatch\u001b[38;5;241m=\u001b[39mhatch)\n",
      "File \u001b[0;32m~/Documents/KTH/master-thesis/codebase/twiga/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/KTH/master-thesis/codebase/twiga/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4209\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4203\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4206\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4207\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4208\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 4209\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[1;32m   4212\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   4213\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/KTH/master-thesis/codebase/twiga/.venv/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'baseline'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # here I should create a plot of the averages with the error bars\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# results_df.index = ['Baseline', 'Assistant', 'Pipeline']\n",
    "# standard_errors_df.index = ['Baseline', 'Assistant', 'Pipeline']\n",
    "\n",
    "# # Define shades of grey and patterns\n",
    "# colors = ['#808080', '#A9A9A9', '#D3D3D3']  # Different shades of grey\n",
    "# hatches = ['/', '\\\\', '|']  # Different patterns\n",
    "\n",
    "# # Create a single plot\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# metrics = ['answer_relevance', 'formulation', 'suitability']\n",
    "# titles = ['Answer Relevance', 'Formulation', 'Suitability']\n",
    "# pipelines = ['Baseline', 'Assistant', 'Pipeline']\n",
    "\n",
    "# # Positions for the bars\n",
    "# bar_width = 0.2\n",
    "# positions = np.arange(len(pipelines))\n",
    "# offsets = np.linspace(-bar_width, bar_width, len(metrics))\n",
    "\n",
    "# # Plotting\n",
    "# for i, (metric, title, color, hatch) in enumerate(zip(metrics, titles, colors, hatches)):\n",
    "#     means = [results_df.loc[pipeline, metric] for pipeline in pipelines]\n",
    "#     errors = [standard_errors_df.loc[pipeline, metric] for pipeline in pipelines]\n",
    "#     bars = ax.bar(positions + offsets[i], means, yerr=errors, capsize=5, width=bar_width, color=color, label=title, hatch=hatch)\n",
    "\n",
    "# # Customizing the plot\n",
    "# ax.set_title('Comparison of RAG Pipelines')\n",
    "# ax.set_ylim(0, 5)\n",
    "# ax.set_ylabel('Average Score (Likert)')\n",
    "# ax.set_xlabel('Generation Architecture')\n",
    "# ax.set_xticks(positions)\n",
    "# ax.set_xticklabels(['Baseline (no retrieval)', 'OpenAI assistant', 'Twiga pipeline'])\n",
    "# ax.legend()\n",
    "\n",
    "# plt.tight_layout(rect=[0, 1, 1, 0.6])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define colors and patterns\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, Orange, Green\n",
    "hatches = ['/', '\\\\', '|']  # Different patterns\n",
    "\n",
    "# Create a single plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "metrics = ['answer_relevance', 'formulation', 'suitability']\n",
    "titles = ['Answer Relevance', 'Formulation', 'Suitability']\n",
    "pipelines = ['Baseline', 'Assistant', 'Pipeline']\n",
    "\n",
    "# Positions for the bars\n",
    "bar_width = 0.2\n",
    "positions = np.arange(len(pipelines))\n",
    "offsets = np.linspace(-bar_width, bar_width, len(metrics))\n",
    "\n",
    "# Plotting\n",
    "for i, (metric, title, color, hatch) in enumerate(zip(metrics, titles, colors, hatches)):\n",
    "    means = [results_df.loc[pipeline, metric] for pipeline in pipelines]\n",
    "    errors = [standard_errors_df.loc[pipeline, metric] for pipeline in pipelines]\n",
    "    bars = ax.bar(positions + offsets[i], means, yerr=errors, capsize=5, width=bar_width, color=color, label=title, hatch=hatch)\n",
    "    \n",
    "    # Adding data labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 18),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Customizing the plot\n",
    "ax.set_ylim(1, 5)\n",
    "ax.set_ylabel('Average Score (Likert)', fontsize=14)\n",
    "ax.set_xlabel('Generation Architecture', fontsize=14)\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(['Baseline (no retrieval)', 'OpenAI assistant', 'Twiga pipeline'], fontsize=12)\n",
    "ax.legend(title='Metrics', title_fontsize='13', fontsize='11', loc='lower center', bbox_to_anchor=(0.5, 0.87), ncol=3)\n",
    "\n",
    "# Add grid lines\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 1],h_pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Krippendorf's alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_16298/1251106025.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pivot_answer_relevance = pivot_answer_relevance.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_16298/1251106025.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pivot_formulation = pivot_formulation.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_16298/1251106025.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pivot_suitability = pivot_suitability.applymap(lambda x: np.nan if pd.isnull(x) else x)\n"
     ]
    }
   ],
   "source": [
    "import krippendorff\n",
    "\n",
    "# Prepare data for the Krippendorf calculation\n",
    "\n",
    "df1 = pd.read_csv(\"../../evals/human/multi-dimension/results/assistant_results.csv\")\n",
    "df2 = pd.read_csv(\"../../evals/human/multi-dimension/results/baseline_results.csv\")\n",
    "df3 = pd.read_csv(\"../../evals/human/multi-dimension/results/pipeline_results.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "# Create three pivot tables, one for each metric (the aggfunc is only used to deal with duplicate question_number-respondent pairs)\n",
    "pivot_answer_relevance = df.pivot_table(index='respondent', columns='question_number', values='answer_relevance', aggfunc='mean')\n",
    "pivot_formulation = df.pivot_table(index='respondent', columns='question_number', values='formulation', aggfunc='mean')\n",
    "pivot_suitability = df.pivot_table(index='respondent', columns='question_number', values='suitability', aggfunc='mean')\n",
    "\n",
    "# Replace missing values with np.nan\n",
    "pivot_answer_relevance = pivot_answer_relevance.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
    "pivot_formulation = pivot_formulation.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
    "pivot_suitability = pivot_suitability.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
    "\n",
    "# Convert pivot tables to numpy arrays\n",
    "array_answer_relevance = pivot_answer_relevance.to_numpy()\n",
    "array_formulation = pivot_formulation.to_numpy()\n",
    "array_suitability = pivot_suitability.to_numpy()\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    # Print the arrays to check\n",
    "    print(\"Answer Relevance Array:\")\n",
    "    print(array_answer_relevance)\n",
    "    print(\"\\nFormulation Array:\")\n",
    "    print(array_formulation)\n",
    "    print(\"\\nSuitability Array:\")\n",
    "    print(array_suitability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020153432197979382 0.1372956309736706 0.3243691954022989\n"
     ]
    }
   ],
   "source": [
    "# Calculate Krippendorff's alpha for each question\n",
    "alpha_answer_relevance = krippendorff.alpha(reliability_data=array_answer_relevance, level_of_measurement=\"ordinal\")\n",
    "alpha_formulation = krippendorff.alpha(reliability_data=array_formulation, level_of_measurement=\"ordinal\")\n",
    "alpha_suitability = krippendorff.alpha(reliability_data=array_suitability, level_of_measurement=\"ordinal\")\n",
    "\n",
    "print(alpha_answer_relevance, alpha_formulation, alpha_suitability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
