{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute PC survey results\n",
    "\n",
    "This document will allow us to compute the PC values from the users and Krippendorf's alpha between them (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "csv_pc_1_path = \"../../evals/human/pairwise-comparison/results/twiga-pc-1.csv\"\n",
    "csv_pc_2_path = \"../../evals/human/pairwise-comparison/results/twiga-pc-2.csv\"\n",
    "csv_pc_3_path = \"../../evals/human/pairwise-comparison/results/twiga-pc-3.csv\"\n",
    "json_pc_1_path = \"../../evals/human/pairwise-comparison/pairwise-comparison-survey-part-1.json\"\n",
    "json_pc_2_path = \"../../evals/human/pairwise-comparison/pairwise-comparison-survey-part-2.json\"\n",
    "json_pc_3_path = \"../../evals/human/pairwise-comparison/pairwise-comparison-survey-part-3.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the question list to a DataFrame per questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['query', 'human_response', 'response', 'exercise_format', 'topic',\n",
      "       'source_file'],\n",
      "      dtype='object')\n",
      "Index(['query', 'human_response', 'response', 'exercise_format', 'topic',\n",
      "       'source_file'],\n",
      "      dtype='object')\n",
      "Index(['query', 'human_response', 'response', 'exercise_format', 'topic',\n",
      "       'source_file'],\n",
      "      dtype='object')\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read JSON file of queries into three separate pc survey dataframes\"\"\"\n",
    "# Extract the relevant information and store it in a dictionary\n",
    "pc_queries_1_df = pd.read_json(json_pc_1_path)\n",
    "pc_queries_2_df = pd.read_json(json_pc_2_path)\n",
    "pc_queries_3_df = pd.read_json(json_pc_3_path)\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    print(pc_queries_1_df.columns)\n",
    "    print(pc_queries_2_df.columns)\n",
    "    print(pc_queries_3_df.columns)\n",
    "\n",
    "    print(len(pc_queries_1_df))\n",
    "    print(len(pc_queries_2_df))\n",
    "    print(len(pc_queries_3_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pairwise-comparison surveys into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   question_number                            respondent  preferred_answer\n",
      "0               Q3  dba7bed2-5205-4cf7-8c0c-124a91888879                 0\n",
      "1               Q4  dba7bed2-5205-4cf7-8c0c-124a91888879                 0\n",
      "2               Q5  dba7bed2-5205-4cf7-8c0c-124a91888879                 0\n",
      "3               Q6  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "4               Q7  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "5               Q8  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "6               Q9  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "7              Q10  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "8              Q11  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "9              Q12  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "10             Q13  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "11             Q14  dba7bed2-5205-4cf7-8c0c-124a91888879                 1\n",
      "12              Q3  74fb53d9-22ae-4d19-84d9-982576d55edd                 0\n",
      "13              Q4  74fb53d9-22ae-4d19-84d9-982576d55edd                 0\n",
      "14              Q5  74fb53d9-22ae-4d19-84d9-982576d55edd                 0\n",
      "15              Q6  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "16              Q7  74fb53d9-22ae-4d19-84d9-982576d55edd                 0\n",
      "17              Q8  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "18              Q9  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "19             Q10  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "20             Q11  74fb53d9-22ae-4d19-84d9-982576d55edd                 0\n",
      "21             Q12  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "22             Q13  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "23             Q14  74fb53d9-22ae-4d19-84d9-982576d55edd                 1\n",
      "24              Q3  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 0\n",
      "25              Q4  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 1\n",
      "26              Q5  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 0\n",
      "27              Q6  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 0\n",
      "28              Q7  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 0\n",
      "29              Q8  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 1\n",
      "30              Q9  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 0\n",
      "31             Q10  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 0\n",
      "32             Q11  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 1\n",
      "33             Q12  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 1\n",
      "34             Q13  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 1\n",
      "35             Q14  4f9670b5-cf5f-4aed-abba-de5c94b02c46                 1\n",
      "36              Q3  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 0\n",
      "37              Q4  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 0\n",
      "38              Q5  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "39              Q6  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "40              Q7  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 0\n",
      "41              Q8  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 0\n",
      "42              Q9  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "43             Q10  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "44             Q11  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "45             Q12  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "46             Q13  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "47             Q14  5d736fe3-8f1f-4a6e-90c7-a268eca5fb59                 1\n",
      "   question_number                            respondent  preferred_answer\n",
      "0               Q3  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "1               Q4  24364e10-e675-46cf-8643-39804f6bd06f                 0\n",
      "2               Q5  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "3               Q6  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "4               Q7  24364e10-e675-46cf-8643-39804f6bd06f                 0\n",
      "5               Q8  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "6               Q9  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "7              Q10  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "8              Q11  24364e10-e675-46cf-8643-39804f6bd06f                 0\n",
      "9              Q12  24364e10-e675-46cf-8643-39804f6bd06f                 0\n",
      "10             Q13  24364e10-e675-46cf-8643-39804f6bd06f                 0\n",
      "11             Q14  24364e10-e675-46cf-8643-39804f6bd06f                 1\n",
      "12              Q3  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "13              Q4  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 0\n",
      "14              Q5  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "15              Q6  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "16              Q7  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 0\n",
      "17              Q8  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 0\n",
      "18              Q9  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "19             Q10  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "20             Q11  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "21             Q12  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 0\n",
      "22             Q13  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 0\n",
      "23             Q14  1f72e6c3-aefc-4d6a-9a5e-dd856e39c4d6                 1\n",
      "24              Q3  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 1\n",
      "25              Q4  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 0\n",
      "26              Q5  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 0\n",
      "27              Q6  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 1\n",
      "28              Q7  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 1\n",
      "29              Q8  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 0\n",
      "30              Q9  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 1\n",
      "31             Q10  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 0\n",
      "32             Q11  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 1\n",
      "33             Q12  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 0\n",
      "34             Q13  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 0\n",
      "35             Q14  6231f0db-81d1-40f9-a421-ce3cc73a81ab                 1\n",
      "   question_number                            respondent  preferred_answer\n",
      "0               Q3  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 1\n",
      "1               Q4  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 0\n",
      "2               Q5  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 0\n",
      "3               Q6  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 1\n",
      "4               Q7  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 0\n",
      "5               Q8  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 0\n",
      "6               Q9  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 1\n",
      "7              Q10  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 1\n",
      "8              Q11  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 0\n",
      "9              Q12  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 0\n",
      "10             Q13  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 1\n",
      "11             Q14  0cb6c38c-3fe2-4aae-9f60-62f1be965c39                 1\n",
      "12              Q3  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "13              Q4  ed985daf-f250-4e84-a858-4a5af32df407                 0\n",
      "14              Q5  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "15              Q6  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "16              Q7  ed985daf-f250-4e84-a858-4a5af32df407                 0\n",
      "17              Q8  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "18              Q9  ed985daf-f250-4e84-a858-4a5af32df407                 0\n",
      "19             Q10  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "20             Q11  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "21             Q12  ed985daf-f250-4e84-a858-4a5af32df407                 0\n",
      "22             Q13  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "23             Q14  ed985daf-f250-4e84-a858-4a5af32df407                 1\n",
      "24              Q3  7a042cf8-79f3-41d4-a45b-a65d31501b39                 1\n",
      "25              Q4  7a042cf8-79f3-41d4-a45b-a65d31501b39                 0\n",
      "26              Q5  7a042cf8-79f3-41d4-a45b-a65d31501b39                 1\n",
      "27              Q6  7a042cf8-79f3-41d4-a45b-a65d31501b39                 1\n",
      "28              Q7  7a042cf8-79f3-41d4-a45b-a65d31501b39                 0\n",
      "29              Q8  7a042cf8-79f3-41d4-a45b-a65d31501b39                 0\n",
      "30              Q9  7a042cf8-79f3-41d4-a45b-a65d31501b39                 1\n",
      "31             Q10  7a042cf8-79f3-41d4-a45b-a65d31501b39                 1\n",
      "32             Q11  7a042cf8-79f3-41d4-a45b-a65d31501b39                 0\n",
      "33             Q12  7a042cf8-79f3-41d4-a45b-a65d31501b39                 0\n",
      "34             Q13  7a042cf8-79f3-41d4-a45b-a65d31501b39                 0\n",
      "35             Q14  7a042cf8-79f3-41d4-a45b-a65d31501b39                 1\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame, skipping two unnecessary rows\n",
    "\n",
    "pc_responses_1_df = pd.read_csv(csv_pc_1_path, skiprows=[1,2])\n",
    "pc_responses_2_df = pd.read_csv(csv_pc_2_path, skiprows=[1,2])\n",
    "pc_responses_3_df = pd.read_csv(csv_pc_3_path, skiprows=[1,2])\n",
    "\n",
    "# This should be the same for all three surveys as they are essentially identical\n",
    "name_column = pc_responses_2_df.columns[17]  # The title of the name column\n",
    "sanity_check_columns = pc_responses_2_df.columns[21:24] # TODO: get the actual query-response pairs I made manually and show them somewhere along with these (can put in appendix)\n",
    "response_columns = pc_responses_2_df.columns[24:36] # The titles of the question columns and associated responses\n",
    "\n",
    "def fill_data(pc_df: pd.DataFrame, num_respondents:int) -> pd.DataFrame:\n",
    "    data_dict = {\n",
    "        \"question_number\": [\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9\",\"Q10\",\"Q11\",\"Q12\",\"Q13\",\"Q14\"]*num_respondents,\n",
    "        \"respondent\": [],\n",
    "        \"preferred_answer\": [], # this is a 1 or a 0, if its a 1 then the second response was preferred and 0 if the first was preferred\n",
    "    }\n",
    "    for _, row in pc_df.iterrows():\n",
    "        name = row[name_column]\n",
    "        name = uuid.uuid4() # TODO: make the ID the same as in the previous survey! Can just do this manually\n",
    "        responses = row[response_columns].tolist()\n",
    "        \n",
    "        preferred_answer_responses = [int(res)-1 for res in responses]\n",
    "        \n",
    "        for pa in preferred_answer_responses:\n",
    "            data_dict[\"respondent\"].append(name)\n",
    "            data_dict[\"preferred_answer\"].append(pa)\n",
    "    \n",
    "    return pd.DataFrame(data_dict)\n",
    "\n",
    "pc_1_data_df = fill_data(pc_responses_1_df, 4)\n",
    "pc_2_data_df = fill_data(pc_responses_2_df, 3)\n",
    "pc_3_data_df = fill_data(pc_responses_3_df, 3)\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    print(pc_1_data_df)\n",
    "    print(pc_2_data_df)\n",
    "    print(pc_3_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the questions with the responses in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First expand the queries DataFrames to be the same length as the response DataFrames\n",
    "pc_queries_1_df_expanded = pd.concat([pc_queries_1_df] * 4, ignore_index=True) # note that the first survey has 4 respondents\n",
    "pc_queries_2_df_expanded = pd.concat([pc_queries_2_df] * 3, ignore_index=True)\n",
    "pc_queries_3_df_expanded = pd.concat([pc_queries_3_df] * 3, ignore_index=True)\n",
    "\n",
    "# Concatenate the DataFrames along the columns\n",
    "pc_queries_1_complete = pd.concat([pc_queries_1_df_expanded, pc_1_data_df], axis=1)\n",
    "pc_queries_2_complete = pd.concat([pc_queries_2_df_expanded, pc_2_data_df], axis=1)\n",
    "pc_queries_3_complete = pd.concat([pc_queries_3_df_expanded, pc_3_data_df], axis=1)\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    print(pc_queries_1_complete.columns)\n",
    "    print(pc_queries_2_complete.columns)\n",
    "    print(pc_queries_3_complete.columns)\n",
    "\n",
    "pc_queries_1_complete.to_csv(\"../../evals/human/pairwise-comparison/results/data1.csv\")\n",
    "pc_queries_2_complete.to_csv(\"../../evals/human/pairwise-comparison/results/data2.csv\")\n",
    "pc_queries_3_complete.to_csv(\"../../evals/human/pairwise-comparison/results/data3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index of questions per model and position per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check this directly in the survey\n",
    "pc_survey_1_index = {\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": {\n",
    "        \"locations\": [0,2,5,11],\n",
    "        \"model_response_number\": [1,1,0,0]\n",
    "    },\n",
    "    \"pipeline-gpt-4-1106-preview\":{\n",
    "        \"locations\": [1,4,6,7,10],\n",
    "        \"model_response_number\": [0,0,1,1,1]\n",
    "    },\n",
    "    \"pipeline-llama-3-70B-instruct\":{\n",
    "        \"locations\": [3,8,9],\n",
    "        \"model_response_number\": [1,0,0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Double check this directly in the survey\n",
    "pc_survey_2_index = {\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": {\n",
    "            \"locations\": [1,3,4,8,10],\n",
    "            \"model_response_number\": [0,1,0,0,1]\n",
    "        },\n",
    "    \"pipeline-gpt-4-1106-preview\": {\n",
    "            \"locations\": [0,9,11],\n",
    "            \"model_response_number\": [1,0,0]\n",
    "        },\n",
    "    \"pipeline-llama-3-70B-instruct\": {\n",
    "            \"locations\": [2,5,6,7],\n",
    "            \"model_response_number\": [1,0,1,1]\n",
    "        }\n",
    "}\n",
    "\n",
    "# Double check this directly in the survey\n",
    "pc_survey_3_index = {\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": {\n",
    "            \"locations\": [6,7,9],\n",
    "            \"model_response_number\": [1,1,0]\n",
    "        },\n",
    "    \"pipeline-gpt-4-1106-preview\": {\n",
    "            \"locations\": [2,3,5,8],\n",
    "            \"model_response_number\": [1,1,0,0]\n",
    "        },\n",
    "    \"pipeline-llama-3-70B-instruct\": {\n",
    "            \"locations\": [0,1,4,10,11],\n",
    "            \"model_response_number\": [1,0,0,1,0]\n",
    "        }\n",
    "}\n",
    "\n",
    "QUESTION_ID_CONVERSION = {\n",
    "    0: \"Q3\",\n",
    "    1: \"Q4\",\n",
    "    2: \"Q5\",\n",
    "    3: \"Q6\",\n",
    "    4: \"Q7\",\n",
    "    5: \"Q8\",\n",
    "    6: \"Q9\",\n",
    "    7: \"Q10\",\n",
    "    8: \"Q11\",\n",
    "    9: \"Q12\",\n",
    "    10: \"Q13\",\n",
    "    11: \"Q14\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the relevant results per pipeline (first off gpt-3-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2700575773.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_1['model_res_number'] = pipeline_gpt35_df_1['question_number'].map(model_response_dict_1)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2700575773.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_2['model_res_number'] = pipeline_gpt35_df_2['question_number'].map(model_response_dict_2)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2700575773.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_3['model_res_number'] = pipeline_gpt35_df_3['question_number'].map(model_response_dict_3)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2700575773.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_1['question_number'] = pipeline_gpt35_df_1['question_number']+\"-survey-1\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2700575773.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_2['question_number'] = pipeline_gpt35_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2700575773.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_3['question_number'] = pipeline_gpt35_df_3['question_number']+\"-survey-3\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the relevant gpt-3-5 questions from each survey\"\"\"\n",
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"]]\n",
    "\n",
    "model_response_number_index_1 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"model_response_number\"],pc_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"])]\n",
    "model_response_number_index_2 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"model_response_number\"],pc_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"])]\n",
    "model_response_number_index_3 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"model_response_number\"],pc_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"])]\n",
    "\n",
    "# Create dictionaries\n",
    "model_response_dict_1 = dict(model_response_number_index_1)\n",
    "model_response_dict_2 = dict(model_response_number_index_2)\n",
    "model_response_dict_3 = dict(model_response_number_index_3)\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'question_number' column matches any name in the list\n",
    "pipeline_gpt35_df_1 = pc_queries_1_complete[pc_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_gpt35_df_2 = pc_queries_2_complete[pc_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "pipeline_gpt35_df_3 = pc_queries_3_complete[pc_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Map the 'question_number' to 'model_res_number' using the dictionary\n",
    "pipeline_gpt35_df_1['model_res_number'] = pipeline_gpt35_df_1['question_number'].map(model_response_dict_1)\n",
    "pipeline_gpt35_df_2['model_res_number'] = pipeline_gpt35_df_2['question_number'].map(model_response_dict_2)\n",
    "pipeline_gpt35_df_3['model_res_number'] = pipeline_gpt35_df_3['question_number'].map(model_response_dict_3)\n",
    "\n",
    "# Update the question_number identifiers\n",
    "pipeline_gpt35_df_1['question_number'] = pipeline_gpt35_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_gpt35_df_2['question_number'] = pipeline_gpt35_df_2['question_number']+\"-survey-2\"\n",
    "pipeline_gpt35_df_3['question_number'] = pipeline_gpt35_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "# pipeline_df_gpt35 = pipeline_gpt35_df_2\n",
    "pipeline_df_gpt35 = pd.concat([pipeline_gpt35_df_1, pipeline_gpt35_df_2, pipeline_gpt35_df_3], axis=0, ignore_index=True)\n",
    "# pipeline_df_gpt35 = pd.concat([pipeline_gpt35_df_2, pipeline_gpt35_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "\"\"\"Compute the model score for all the gpt-3.5 responses across the three surveys by comparing pref answer and model res number\"\"\"\n",
    "# Perform the AND operation and create the final column\n",
    "pipeline_df_gpt35['model_score'] = pipeline_df_gpt35['preferred_answer'] == pipeline_df_gpt35['model_res_number']\n",
    "\n",
    "# Convert boolean values to integers\n",
    "pipeline_df_gpt35['model_score'] = pipeline_df_gpt35['model_score'].astype(int)\n",
    "pipeline_df_gpt35['preferred_answer'] = pipeline_df_gpt35['preferred_answer'].astype(int)\n",
    "pipeline_df_gpt35['model_res_number'] = pipeline_df_gpt35['model_res_number'].astype(int)\n",
    "\n",
    "pipeline_df_gpt35.to_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt3_5_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (now for GPT-4 pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2095684581.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_1['model_res_number'] = pipeline_gpt4_df_1['question_number'].map(model_response_dict_1)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2095684581.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_2['model_res_number'] = pipeline_gpt4_df_2['question_number'].map(model_response_dict_2)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2095684581.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_3['model_res_number'] = pipeline_gpt4_df_3['question_number'].map(model_response_dict_3)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2095684581.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_1['question_number'] = pipeline_gpt4_df_1['question_number']+\"-survey-1\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2095684581.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_2['question_number'] = pipeline_gpt4_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2095684581.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_3['question_number'] = pipeline_gpt4_df_3['question_number']+\"-survey-3\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the relevant gpt-4 questions from each survey\"\"\"\n",
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_1_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_2_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_3_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"]]\n",
    "\n",
    "model_response_number_index_1 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_1_index[\"pipeline-gpt-4-1106-preview\"][\"model_response_number\"],pc_survey_1_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"])]\n",
    "model_response_number_index_2 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_2_index[\"pipeline-gpt-4-1106-preview\"][\"model_response_number\"],pc_survey_2_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"])]\n",
    "model_response_number_index_3 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_3_index[\"pipeline-gpt-4-1106-preview\"][\"model_response_number\"],pc_survey_3_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"])]\n",
    "\n",
    "# Create dictionaries\n",
    "model_response_dict_1 = dict(model_response_number_index_1)\n",
    "model_response_dict_2 = dict(model_response_number_index_2)\n",
    "model_response_dict_3 = dict(model_response_number_index_3)\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'question_number' column matches any name in the list\n",
    "pipeline_gpt4_df_1 = pc_queries_1_complete[pc_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_gpt4_df_2 = pc_queries_2_complete[pc_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "pipeline_gpt4_df_3 = pc_queries_3_complete[pc_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Map the 'question_number' to 'model_res_number' using the dictionary\n",
    "pipeline_gpt4_df_1['model_res_number'] = pipeline_gpt4_df_1['question_number'].map(model_response_dict_1)\n",
    "pipeline_gpt4_df_2['model_res_number'] = pipeline_gpt4_df_2['question_number'].map(model_response_dict_2)\n",
    "pipeline_gpt4_df_3['model_res_number'] = pipeline_gpt4_df_3['question_number'].map(model_response_dict_3)\n",
    "\n",
    "# Update the question_number identifiers\n",
    "pipeline_gpt4_df_1['question_number'] = pipeline_gpt4_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_gpt4_df_2['question_number'] = pipeline_gpt4_df_2['question_number']+\"-survey-2\"\n",
    "pipeline_gpt4_df_3['question_number'] = pipeline_gpt4_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "# pipeline_df_gpt4 = pipeline_gpt4_df_2\n",
    "pipeline_df_gpt4 = pd.concat([pipeline_gpt4_df_1, pipeline_gpt4_df_2, pipeline_gpt4_df_3], axis=0, ignore_index=True)\n",
    "# pipeline_df_gpt4 = pd.concat([pipeline_gpt4_df_2, pipeline_gpt4_df_3], axis=0, ignore_index=True) # to see without first survey\n",
    "\n",
    "\"\"\"Compute the model score for all the gpt-3.5 responses across the three surveys by comparing pref answer and model res number\"\"\"\n",
    "# Perform the AND operation and create the final column\n",
    "pipeline_df_gpt4['model_score'] = pipeline_df_gpt4['preferred_answer'] == pipeline_df_gpt4['model_res_number']\n",
    "\n",
    "# Convert boolean values to integers\n",
    "pipeline_df_gpt4['model_score'] = pipeline_df_gpt4['model_score'].astype(int)\n",
    "pipeline_df_gpt4['preferred_answer'] = pipeline_df_gpt4['preferred_answer'].astype(int)\n",
    "pipeline_df_gpt4['model_res_number'] = pipeline_df_gpt4['model_res_number'].astype(int)\n",
    "\n",
    "pipeline_df_gpt4.to_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt4_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (now for Llama3 pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2149815106.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_1['model_res_number'] = pipeline_llama3_df_1['question_number'].map(model_response_dict_1)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2149815106.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_2['model_res_number'] = pipeline_llama3_df_2['question_number'].map(model_response_dict_2)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2149815106.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_3['model_res_number'] = pipeline_llama3_df_3['question_number'].map(model_response_dict_3)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2149815106.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_1['question_number'] = pipeline_llama3_df_1['question_number']+\"-survey-1\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2149815106.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_2['question_number'] = pipeline_llama3_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2149815106.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_3['question_number'] = pipeline_llama3_df_3['question_number']+\"-survey-3\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the relevant llama3 questions from each survey\"\"\"\n",
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_1_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_2_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_3_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"]]\n",
    "\n",
    "model_response_number_index_1 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_1_index[\"pipeline-llama-3-70B-instruct\"][\"model_response_number\"],pc_survey_1_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"])]\n",
    "model_response_number_index_2 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_2_index[\"pipeline-llama-3-70B-instruct\"][\"model_response_number\"],pc_survey_2_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"])]\n",
    "model_response_number_index_3 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_3_index[\"pipeline-llama-3-70B-instruct\"][\"model_response_number\"],pc_survey_3_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"])]\n",
    "\n",
    "# Create dictionaries\n",
    "model_response_dict_1 = dict(model_response_number_index_1)\n",
    "model_response_dict_2 = dict(model_response_number_index_2)\n",
    "model_response_dict_3 = dict(model_response_number_index_3)\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'question_number' column matches any name in the list\n",
    "pipeline_llama3_df_1 = pc_queries_1_complete[pc_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_llama3_df_2 = pc_queries_2_complete[pc_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "pipeline_llama3_df_3 = pc_queries_3_complete[pc_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Map the 'question_number' to 'model_res_number' using the dictionary\n",
    "pipeline_llama3_df_1['model_res_number'] = pipeline_llama3_df_1['question_number'].map(model_response_dict_1)\n",
    "pipeline_llama3_df_2['model_res_number'] = pipeline_llama3_df_2['question_number'].map(model_response_dict_2)\n",
    "pipeline_llama3_df_3['model_res_number'] = pipeline_llama3_df_3['question_number'].map(model_response_dict_3)\n",
    "\n",
    "# Update the question_number identifiers\n",
    "pipeline_llama3_df_1['question_number'] = pipeline_llama3_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_llama3_df_2['question_number'] = pipeline_llama3_df_2['question_number']+\"-survey-2\"\n",
    "pipeline_llama3_df_3['question_number'] = pipeline_llama3_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "# pipeline_df_llama3 = pipeline_llama3_df_2\n",
    "pipeline_df_llama3 = pd.concat([pipeline_llama3_df_1, pipeline_llama3_df_2, pipeline_llama3_df_3], axis=0, ignore_index=True)\n",
    "# pipeline_df_llama3 = pd.concat([pipeline_llama3_df_2, pipeline_llama3_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "\"\"\"Compute the model score for all the gpt-3.5 responses across the three surveys by comparing pref answer and model res number\"\"\"\n",
    "# Perform the AND operation and create the final column\n",
    "pipeline_df_llama3['model_score'] = pipeline_df_llama3['preferred_answer'] == pipeline_df_llama3['model_res_number']\n",
    "\n",
    "# Convert boolean values to integers\n",
    "pipeline_df_llama3['model_score'] = pipeline_df_llama3['model_score'].astype(int)\n",
    "pipeline_df_llama3['preferred_answer'] = pipeline_df_llama3['preferred_answer'].astype(int)\n",
    "pipeline_df_llama3['model_res_number'] = pipeline_df_llama3['model_res_number'].astype(int)\n",
    "\n",
    "pipeline_df_llama3.to_csv(\"../../evals/human/pairwise-comparison/results/pipeline_llama3_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get values of interest from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages (0=gpt3.5, 1=gpt4, 2=llama3)\n",
      "   human_score  model_score\n",
      "0     0.291667     0.708333\n",
      "1     0.285714     0.714286\n",
      "2     0.259259     0.740741\n"
     ]
    }
   ],
   "source": [
    "pipeline_gpt35_results = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt3_5_results.csv\")\n",
    "pipeline_gpt4_results = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt4_results.csv\")\n",
    "pipeline_llama3_results = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_llama3_results.csv\")\n",
    "\n",
    "pipeline_gpt35_average = pipeline_gpt35_results.groupby('source_file')[['model_score']].mean()\n",
    "pipeline_gpt4_average = pipeline_gpt4_results.groupby('source_file')[['model_score']].mean()\n",
    "pipeline_llama3_average = pipeline_llama3_results.groupby('source_file')[['model_score']].mean()\n",
    "\n",
    "results_df = pd.concat([pipeline_gpt35_average, pipeline_gpt4_average, pipeline_llama3_average], axis=0, ignore_index=True)\n",
    "results_df[\"human_score\"] = 1.0 - results_df[\"model_score\"]\n",
    "\n",
    "# Specify the new column order\n",
    "new_column_order = ['human_score', 'model_score']\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "results_df = results_df[new_column_order]\n",
    "\n",
    "print(\"Averages (0=gpt3.5, 1=gpt4, 2=llama3)\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute standard error of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mean (0=gpt3_5, 1=gpt4, 2=llama3)\n",
      "   model_score\n",
      "0     0.094776\n",
      "1     0.101015\n",
      "2     0.085944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2956605284.py:15: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  sem_gpt3_5 = gpt3_5_stds / np.sqrt(int(n_respondents_gpt35))\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2956605284.py:16: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  sem_gpt4 = gpt4_stds / np.sqrt(int(n_respondents_gpt4))\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/2956605284.py:17: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  sem_llama3 = llama3_stds / np.sqrt(int(n_respondents_llama3))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate standard deviations\n",
    "gpt3_5_stds = pipeline_gpt35_results.groupby('source_file')[['model_score']].std()\n",
    "gpt4_stds = pipeline_gpt4_results.groupby('source_file')[['model_score']].std()\n",
    "llama3_stds = pipeline_llama3_results.groupby('source_file')[['model_score']].std()\n",
    "\n",
    "# Number of respondents per pipeline (assuming equal number of responses per pipeline for simplicity)\n",
    "n_respondents_gpt35 = pipeline_gpt35_results.groupby('source_file').size()\n",
    "n_respondents_gpt4 = pipeline_gpt4_results.groupby('source_file').size()\n",
    "n_respondents_llama3 = pipeline_llama3_results.groupby('source_file').size()\n",
    "\n",
    "\n",
    "# Calculate standard error of the mean (SEM) - \n",
    "sem_gpt3_5 = gpt3_5_stds / np.sqrt(int(n_respondents_gpt35))\n",
    "sem_gpt4 = gpt4_stds / np.sqrt(int(n_respondents_gpt4))\n",
    "sem_llama3 = llama3_stds / np.sqrt(int(n_respondents_llama3))\n",
    "\n",
    "standard_errors_df = pd.concat([sem_gpt3_5, sem_gpt4, sem_llama3], axis=0, ignore_index=True)\n",
    "print(\"Standard mean (0=gpt3_5, 1=gpt4, 2=llama3)\")\n",
    "print(standard_errors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute krippendorffs alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred Answer Array:\n",
      "[[nan  1. nan  0. nan  0. nan  1. nan  1. nan  1. nan  0. nan  0. nan  1.\n",
      "  nan  0. nan  0. nan  1.]\n",
      " [ 1. nan  1. nan  0. nan  0. nan  1. nan  1. nan  0. nan  1. nan  1. nan\n",
      "   0. nan  0. nan  1. nan]\n",
      " [ 1. nan  0. nan  0. nan  0. nan  1. nan  1. nan  0. nan  1. nan  1. nan\n",
      "   0. nan  1. nan  1. nan]\n",
      " [ 0. nan  1. nan  0. nan  0. nan  1. nan  1. nan  0. nan  0. nan  1. nan\n",
      "   1. nan  0. nan  1. nan]\n",
      " [nan  1. nan  0. nan  0. nan  0. nan  1. nan  1. nan  0. nan  1. nan  1.\n",
      "  nan  0. nan  0. nan  1.]\n",
      " [nan  1. nan  1. nan  0. nan  1. nan  1. nan  1. nan  0. nan  1. nan  1.\n",
      "  nan  0. nan  1. nan  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_2516/165693786.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pivot_preferred_answer = pivot_preferred_answer.applymap(lambda x: np.nan if pd.isnull(x) else x)\n"
     ]
    }
   ],
   "source": [
    "import krippendorff\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for the Krippendorf calculation\n",
    "df1 = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt3_5_results.csv\")\n",
    "df2 = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt4_results.csv\")\n",
    "df3 = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_llama3_results.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "# Create three pivot tables, one for each metric (the aggfunc is only used to deal with duplicate question_number-respondent pairs)\n",
    "pivot_preferred_answer = df.pivot_table(index='respondent', columns='question_number', values='preferred_answer', aggfunc='mean')\n",
    "\n",
    "# Replace missing values with np.nan\n",
    "pivot_preferred_answer = pivot_preferred_answer.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
    "\n",
    "# Convert pivot tables to numpy arrays\n",
    "array_preferred_answer = pivot_preferred_answer.to_numpy()\n",
    "\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    # Print the arrays to check\n",
    "    print(\"Preferred Answer Array:\")\n",
    "    print(array_preferred_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4453125\n"
     ]
    }
   ],
   "source": [
    "# Calculate Krippendorff's alpha for each question\n",
    "alpha_preferred_answer = krippendorff.alpha(reliability_data=array_preferred_answer, level_of_measurement=\"ordinal\")\n",
    "\n",
    "print(alpha_preferred_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
