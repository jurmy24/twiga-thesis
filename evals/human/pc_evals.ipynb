{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute PC survey results\n",
    "\n",
    "This document will allow us to compute the PC values from the users and Krippendorf's alpha between them (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "csv_pc_1_path = \"../../evals/human/pairwise-comparison/results/twiga-pc-1.csv\"\n",
    "csv_pc_2_path = \"../../evals/human/pairwise-comparison/results/twiga-pc-2.csv\"\n",
    "csv_pc_3_path = \"../../evals/human/pairwise-comparison/results/twiga-pc-3.csv\"\n",
    "json_pc_1_path = \"../../evals/human/pairwise-comparison/pairwise-comparison-survey-part-1.json\"\n",
    "json_pc_2_path = \"../../evals/human/pairwise-comparison/pairwise-comparison-survey-part-2.json\"\n",
    "json_pc_3_path = \"../../evals/human/pairwise-comparison/pairwise-comparison-survey-part-3.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the question list to a DataFrame per questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['query', 'human_response', 'response', 'exercise_format', 'topic',\n",
      "       'source_file'],\n",
      "      dtype='object')\n",
      "Index(['query', 'human_response', 'response', 'exercise_format', 'topic',\n",
      "       'source_file'],\n",
      "      dtype='object')\n",
      "Index(['query', 'human_response', 'response', 'exercise_format', 'topic',\n",
      "       'source_file'],\n",
      "      dtype='object')\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read JSON file of queries into three separate pc survey dataframes\"\"\"\n",
    "# Extract the relevant information and store it in a dictionary\n",
    "pc_queries_1_df = pd.read_json(json_pc_1_path)\n",
    "pc_queries_2_df = pd.read_json(json_pc_2_path)\n",
    "pc_queries_3_df = pd.read_json(json_pc_3_path)\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    print(pc_queries_1_df.columns)\n",
    "    print(pc_queries_2_df.columns)\n",
    "    print(pc_queries_3_df.columns)\n",
    "\n",
    "    print(len(pc_queries_1_df))\n",
    "    print(len(pc_queries_2_df))\n",
    "    print(len(pc_queries_3_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pairwise-comparison surveys into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   question_number                            respondent  preferred_answer\n",
      "0               Q3  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "1               Q4  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 0\n",
      "2               Q5  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "3               Q6  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "4               Q7  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 0\n",
      "5               Q8  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "6               Q9  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "7              Q10  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "8              Q11  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 0\n",
      "9              Q12  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 0\n",
      "10             Q13  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 0\n",
      "11             Q14  33a7f594-9ffc-46d3-b6ae-60d543baaf30                 1\n",
      "12              Q3  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "13              Q4  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 0\n",
      "14              Q5  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "15              Q6  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "16              Q7  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 0\n",
      "17              Q8  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 0\n",
      "18              Q9  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "19             Q10  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "20             Q11  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "21             Q12  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 0\n",
      "22             Q13  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 0\n",
      "23             Q14  1221f1d9-83b9-42dc-afaf-b359bac3aff9                 1\n",
      "24              Q3  265cb0b4-49a5-430f-b289-f488b612f04a                 1\n",
      "25              Q4  265cb0b4-49a5-430f-b289-f488b612f04a                 0\n",
      "26              Q5  265cb0b4-49a5-430f-b289-f488b612f04a                 0\n",
      "27              Q6  265cb0b4-49a5-430f-b289-f488b612f04a                 1\n",
      "28              Q7  265cb0b4-49a5-430f-b289-f488b612f04a                 1\n",
      "29              Q8  265cb0b4-49a5-430f-b289-f488b612f04a                 0\n",
      "30              Q9  265cb0b4-49a5-430f-b289-f488b612f04a                 1\n",
      "31             Q10  265cb0b4-49a5-430f-b289-f488b612f04a                 0\n",
      "32             Q11  265cb0b4-49a5-430f-b289-f488b612f04a                 1\n",
      "33             Q12  265cb0b4-49a5-430f-b289-f488b612f04a                 0\n",
      "34             Q13  265cb0b4-49a5-430f-b289-f488b612f04a                 0\n",
      "35             Q14  265cb0b4-49a5-430f-b289-f488b612f04a                 1\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame, skipping two unnecessary rows\n",
    "\n",
    "# pc_responses_1_df = pd.read_csv(csv_pc_1_path, skiprows=[1,2])\n",
    "pc_responses_2_df = pd.read_csv(csv_pc_2_path, skiprows=[1,2])\n",
    "# pc_responses_3_df = pd.read_csv(csv_pc_3_path, skiprows=[1,2])\n",
    "\n",
    "# This should be the same for all three surveys as they are essentially identical\n",
    "name_column = pc_responses_2_df.columns[17]  # The title of the name column\n",
    "sanity_check_columns = pc_responses_2_df.columns[21:24] # TODO: get the actual query-response pairs I made manually and show them somewhere along with these (can put in appendix)\n",
    "response_columns = pc_responses_2_df.columns[24:36] # The titles of the question columns and associated responses\n",
    "\n",
    "def fill_data(pc_df: pd.DataFrame, num_respondents:int) -> pd.DataFrame:\n",
    "    data_dict = {\n",
    "        \"question_number\": [\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9\",\"Q10\",\"Q11\",\"Q12\",\"Q13\",\"Q14\"]*num_respondents,\n",
    "        \"respondent\": [],\n",
    "        \"preferred_answer\": [], # this is a 1 or a 0, if its a 1 then the second response was preferred and 0 if the first was preferred\n",
    "    }\n",
    "    for _, row in pc_df.iterrows():\n",
    "        name = row[name_column]\n",
    "        name = uuid.uuid4() # TODO: make the ID the same as in the previous survey! Can just do this manually\n",
    "        responses = row[response_columns].tolist()\n",
    "        \n",
    "        preferred_answer_responses = [int(res)-1 for res in responses]\n",
    "        \n",
    "        for pa in preferred_answer_responses:\n",
    "            data_dict[\"respondent\"].append(name)\n",
    "            data_dict[\"preferred_answer\"].append(pa)\n",
    "    \n",
    "    return pd.DataFrame(data_dict)\n",
    "\n",
    "# pc_1_data_df = fill_data(pc_responses_1_df, 4)\n",
    "pc_2_data_df = fill_data(pc_responses_2_df, 3)\n",
    "# pc_3_data_df = fill_data(pc_responses_3_df, 3)\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    print(pc_2_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the questions with the responses in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First expand the queries DataFrames to be the same length as the response DataFrames\n",
    "# pc_queries_1_df_expanded = pd.concat([pc_queries_1_df] * 4, ignore_index=True) # note that the first survey has 4 respondents\n",
    "pc_queries_2_df_expanded = pd.concat([pc_queries_2_df] * 3, ignore_index=True)\n",
    "# pc_queries_3_df_expanded = pd.concat([pc_queries_3_df] * 3, ignore_index=True)\n",
    "\n",
    "# Concatenate the DataFrames along the columns\n",
    "# pc_queries_1_complete = pd.concat([pc_queries_1_df_expanded, pc_1_data_df], axis=1)\n",
    "pc_queries_2_complete = pd.concat([pc_queries_2_df_expanded, pc_2_data_df], axis=1)\n",
    "# pc_queries_3_complete = pd.concat([pc_queries_3_df_expanded, pc_3_data_df], axis=1)\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    # print(pc_queries_1_complete.columns)\n",
    "    print(pc_queries_2_complete.columns)\n",
    "    # print(pc_queries_3_complete.columns)\n",
    "\n",
    "# pc_queries_1_complete.to_csv(\"../../evals/human/pairwise-comparison/results/data1.csv\")\n",
    "pc_queries_2_complete.to_csv(\"../../evals/human/pairwise-comparison/results/data2.csv\")\n",
    "# pc_queries_3_complete.to_csv(\"../../evals/human/pairwise-comparison/results/data3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index of questions per model and position per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check this directly in the survey\n",
    "pc_survey_1_index = {\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": {\n",
    "        \"locations\": [0,2,5,11],\n",
    "        \"model_response_number\": [1,1,0,0]\n",
    "    },\n",
    "    \"pipeline-gpt-4-1106-preview\":{\n",
    "        \"locations\": [1,4,6,7,10],\n",
    "        \"model_response_number\": [0,0,1,1,1]\n",
    "    },\n",
    "    \"pipeline-llama-3-70B-instruct\":{\n",
    "        \"locations\": [3,8,9],\n",
    "        \"model_response_number\": [1,0,0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Double check this directly in the survey\n",
    "pc_survey_2_index = {\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": {\n",
    "            \"locations\": [1,3,4,8,10],\n",
    "            \"model_response_number\": [0,1,0,0,1]\n",
    "        },\n",
    "    \"pipeline-gpt-4-1106-preview\": {\n",
    "            \"locations\": [0,9,11],\n",
    "            \"model_response_number\": [1,0,0]\n",
    "        },\n",
    "    \"pipeline-llama-3-70B-instruct\": {\n",
    "            \"locations\": [2,5,6,7],\n",
    "            \"model_response_number\": [1,0,1,1]\n",
    "        }\n",
    "}\n",
    "\n",
    "# Double check this directly in the survey\n",
    "pc_survey_3_index = {\n",
    "    \"pipeline-gpt-3-5-turbo-16k-0613\": {\n",
    "            \"locations\": [6,7,9],\n",
    "            \"model_response_number\": [1,1,0]\n",
    "        },\n",
    "    \"pipeline-gpt-4-1106-preview\": {\n",
    "            \"locations\": [2,3,5,8],\n",
    "            \"model_response_number\": [1,1,0,0]\n",
    "        },\n",
    "    \"pipeline-llama-3-70B-instruct\": {\n",
    "            \"locations\": [0,1,4,10,11],\n",
    "            \"model_response_number\": [1,0,0,1,0]\n",
    "        }\n",
    "}\n",
    "\n",
    "QUESTION_ID_CONVERSION = {\n",
    "    0: \"Q3\",\n",
    "    1: \"Q4\",\n",
    "    2: \"Q5\",\n",
    "    3: \"Q6\",\n",
    "    4: \"Q7\",\n",
    "    5: \"Q8\",\n",
    "    6: \"Q9\",\n",
    "    7: \"Q10\",\n",
    "    8: \"Q11\",\n",
    "    9: \"Q12\",\n",
    "    10: \"Q13\",\n",
    "    11: \"Q14\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the relevant results per pipeline (first off gpt-3-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/2755821034.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_2['model_res_number'] = pipeline_gpt35_df_2['question_number'].map(model_response_dict_2)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/2755821034.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt35_df_2['question_number'] = pipeline_gpt35_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/2755821034.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt35['model_score'] = pipeline_df_gpt35['preferred_answer'] == pipeline_df_gpt35['model_res_number']\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/2755821034.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt35['model_score'] = pipeline_df_gpt35['model_score'].astype(int)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/2755821034.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt35['preferred_answer'] = pipeline_df_gpt35['preferred_answer'].astype(int)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/2755821034.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt35['model_res_number'] = pipeline_df_gpt35['model_res_number'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the relevant gpt-3-5 questions from each survey\"\"\"\n",
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"]]\n",
    "\n",
    "model_response_number_index_1 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"model_response_number\"],pc_survey_1_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"])]\n",
    "model_response_number_index_2 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"model_response_number\"],pc_survey_2_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"])]\n",
    "model_response_number_index_3 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"model_response_number\"],pc_survey_3_index[\"pipeline-gpt-3-5-turbo-16k-0613\"][\"locations\"])]\n",
    "\n",
    "# Create dictionaries\n",
    "# model_response_dict_1 = dict(model_response_number_index_1)\n",
    "model_response_dict_2 = dict(model_response_number_index_2)\n",
    "# model_response_dict_3 = dict(model_response_number_index_3)\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'question_number' column matches any name in the list\n",
    "# pipeline_gpt35_df_3 = pc_queries_1_complete[pc_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_gpt35_df_2 = pc_queries_2_complete[pc_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "# pipeline_gpt35_df_3 = pc_queries_3_complete[pc_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Map the 'question_number' to 'model_res_number' using the dictionary\n",
    "# pipeline_gpt35_df_1['model_res_number'] = pipeline_gpt35_df_1['question_number'].map(model_response_dict_1)\n",
    "pipeline_gpt35_df_2['model_res_number'] = pipeline_gpt35_df_2['question_number'].map(model_response_dict_2)\n",
    "# pipeline_gpt35_df_3['model_res_number'] = pipeline_gpt35_df_3['question_number'].map(model_response_dict_3)\n",
    "\n",
    "# Update the question_number identifiers\n",
    "# pipeline_gpt35_df_1['question_number'] = pipeline_gpt35_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_gpt35_df_2['question_number'] = pipeline_gpt35_df_2['question_number']+\"-survey-2\"\n",
    "# pipeline_gpt35_df_3['question_number'] = pipeline_gpt35_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "pipeline_df_gpt35 = pipeline_gpt35_df_2\n",
    "# pipeline_df_gpt35 = pd.concat([pipeline_gpt35_df_1, pipeline_gpt35_df_2, pipeline_gpt35_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "\"\"\"Compute the model score for all the gpt-3.5 responses across the three surveys by comparing pref answer and model res number\"\"\"\n",
    "# Perform the AND operation and create the final column\n",
    "pipeline_df_gpt35['model_score'] = pipeline_df_gpt35['preferred_answer'] == pipeline_df_gpt35['model_res_number']\n",
    "\n",
    "# Convert boolean values to integers\n",
    "pipeline_df_gpt35['model_score'] = pipeline_df_gpt35['model_score'].astype(int)\n",
    "pipeline_df_gpt35['preferred_answer'] = pipeline_df_gpt35['preferred_answer'].astype(int)\n",
    "pipeline_df_gpt35['model_res_number'] = pipeline_df_gpt35['model_res_number'].astype(int)\n",
    "\n",
    "pipeline_df_gpt35.to_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt3_5_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (now for GPT-4 pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/3818648664.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_2['model_res_number'] = pipeline_gpt4_df_2['question_number'].map(model_response_dict_2)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/3818648664.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_gpt4_df_2['question_number'] = pipeline_gpt4_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/3818648664.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt4['model_score'] = pipeline_df_gpt4['preferred_answer'] == pipeline_df_gpt4['model_res_number']\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/3818648664.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt4['model_score'] = pipeline_df_gpt4['model_score'].astype(int)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/3818648664.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt4['preferred_answer'] = pipeline_df_gpt4['preferred_answer'].astype(int)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/3818648664.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_gpt4['model_res_number'] = pipeline_df_gpt4['model_res_number'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the relevant gpt-4 questions from each survey\"\"\"\n",
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_1_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_2_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_3_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"]]\n",
    "\n",
    "model_response_number_index_1 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_1_index[\"pipeline-gpt-4-1106-preview\"][\"model_response_number\"],pc_survey_1_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"])]\n",
    "model_response_number_index_2 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_2_index[\"pipeline-gpt-4-1106-preview\"][\"model_response_number\"],pc_survey_2_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"])]\n",
    "model_response_number_index_3 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_3_index[\"pipeline-gpt-4-1106-preview\"][\"model_response_number\"],pc_survey_3_index[\"pipeline-gpt-4-1106-preview\"][\"locations\"])]\n",
    "\n",
    "# Create dictionaries\n",
    "# model_response_dict_1 = dict(model_response_number_index_1)\n",
    "model_response_dict_2 = dict(model_response_number_index_2)\n",
    "# model_response_dict_3 = dict(model_response_number_index_3)\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'question_number' column matches any name in the list\n",
    "# pipeline_gpt4_df_3 = pc_queries_1_complete[pc_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_gpt4_df_2 = pc_queries_2_complete[pc_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "# pipeline_gpt4_df_3 = pc_queries_3_complete[pc_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Map the 'question_number' to 'model_res_number' using the dictionary\n",
    "# pipeline_gpt4_df_1['model_res_number'] = pipeline_gpt4_df_1['question_number'].map(model_response_dict_1)\n",
    "pipeline_gpt4_df_2['model_res_number'] = pipeline_gpt4_df_2['question_number'].map(model_response_dict_2)\n",
    "# pipeline_gpt4_df_3['model_res_number'] = pipeline_gpt4_df_3['question_number'].map(model_response_dict_3)\n",
    "\n",
    "# Update the question_number identifiers\n",
    "# pipeline_gpt4_df_1['question_number'] = pipeline_gpt4_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_gpt4_df_2['question_number'] = pipeline_gpt4_df_2['question_number']+\"-survey-2\"\n",
    "# pipeline_gpt4_df_3['question_number'] = pipeline_gpt4_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "pipeline_df_gpt4 = pipeline_gpt4_df_2\n",
    "# pipeline_df_gpt4 = pd.concat([pipeline_gpt4_df_1, pipeline_gpt4_df_2, pipeline_gpt4_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "\"\"\"Compute the model score for all the gpt-3.5 responses across the three surveys by comparing pref answer and model res number\"\"\"\n",
    "# Perform the AND operation and create the final column\n",
    "pipeline_df_gpt4['model_score'] = pipeline_df_gpt4['preferred_answer'] == pipeline_df_gpt4['model_res_number']\n",
    "\n",
    "# Convert boolean values to integers\n",
    "pipeline_df_gpt4['model_score'] = pipeline_df_gpt4['model_score'].astype(int)\n",
    "pipeline_df_gpt4['preferred_answer'] = pipeline_df_gpt4['preferred_answer'].astype(int)\n",
    "pipeline_df_gpt4['model_res_number'] = pipeline_df_gpt4['model_res_number'].astype(int)\n",
    "\n",
    "pipeline_df_gpt4.to_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt4_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (now for Llama3 pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/428537372.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_2['model_res_number'] = pipeline_llama3_df_2['question_number'].map(model_response_dict_2)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/428537372.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_llama3_df_2['question_number'] = pipeline_llama3_df_2['question_number']+\"-survey-2\"\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/428537372.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_llama3['model_score'] = pipeline_df_llama3['preferred_answer'] == pipeline_df_llama3['model_res_number']\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/428537372.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_llama3['model_score'] = pipeline_df_llama3['model_score'].astype(int)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/428537372.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_llama3['preferred_answer'] = pipeline_df_llama3['preferred_answer'].astype(int)\n",
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_26093/428537372.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pipeline_df_llama3['model_res_number'] = pipeline_df_llama3['model_res_number'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the relevant llama3 questions from each survey\"\"\"\n",
    "# List of question numbers to match in the respective surveys\n",
    "pipeline_match_1 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_1_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"]]\n",
    "pipeline_match_2 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_2_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"]]\n",
    "pipeline_match_3 = [QUESTION_ID_CONVERSION[location] for location in pc_survey_3_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"]]\n",
    "\n",
    "model_response_number_index_1 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_1_index[\"pipeline-llama-3-70B-instruct\"][\"model_response_number\"],pc_survey_1_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"])]\n",
    "model_response_number_index_2 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_2_index[\"pipeline-llama-3-70B-instruct\"][\"model_response_number\"],pc_survey_2_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"])]\n",
    "model_response_number_index_3 = [(QUESTION_ID_CONVERSION[location], model_res_number) for model_res_number, location in zip(pc_survey_3_index[\"pipeline-llama-3-70B-instruct\"][\"model_response_number\"],pc_survey_3_index[\"pipeline-llama-3-70B-instruct\"][\"locations\"])]\n",
    "\n",
    "# Create dictionaries\n",
    "# model_response_dict_1 = dict(model_response_number_index_1)\n",
    "model_response_dict_2 = dict(model_response_number_index_2)\n",
    "# model_response_dict_3 = dict(model_response_number_index_3)\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'question_number' column matches any name in the list\n",
    "# pipeline_llama3_df_3 = pc_queries_1_complete[pc_queries_1_complete['question_number'].isin(pipeline_match_1)]\n",
    "pipeline_llama3_df_2 = pc_queries_2_complete[pc_queries_2_complete['question_number'].isin(pipeline_match_2)]\n",
    "# pipeline_llama3_df_3 = pc_queries_3_complete[pc_queries_3_complete['question_number'].isin(pipeline_match_3)]\n",
    "\n",
    "# Map the 'question_number' to 'model_res_number' using the dictionary\n",
    "# pipeline_llama3_df_1['model_res_number'] = pipeline_llama3_df_1['question_number'].map(model_response_dict_1)\n",
    "pipeline_llama3_df_2['model_res_number'] = pipeline_llama3_df_2['question_number'].map(model_response_dict_2)\n",
    "# pipeline_llama3_df_3['model_res_number'] = pipeline_llama3_df_3['question_number'].map(model_response_dict_3)\n",
    "\n",
    "# Update the question_number identifiers\n",
    "# pipeline_llama3_df_1['question_number'] = pipeline_llama3_df_1['question_number']+\"-survey-1\"\n",
    "pipeline_llama3_df_2['question_number'] = pipeline_llama3_df_2['question_number']+\"-survey-2\"\n",
    "# pipeline_llama3_df_3['question_number'] = pipeline_llama3_df_3['question_number']+\"-survey-3\"\n",
    "\n",
    "# Concatenate the three DataFrames along the rows\n",
    "pipeline_df_llama3 = pipeline_llama3_df_2\n",
    "# pipeline_df_llama3 = pd.concat([pipeline_llama3_df_1, pipeline_llama3_df_2, pipeline_llama3_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "\"\"\"Compute the model score for all the gpt-3.5 responses across the three surveys by comparing pref answer and model res number\"\"\"\n",
    "# Perform the AND operation and create the final column\n",
    "pipeline_df_llama3['model_score'] = pipeline_df_llama3['preferred_answer'] == pipeline_df_llama3['model_res_number']\n",
    "\n",
    "# Convert boolean values to integers\n",
    "pipeline_df_llama3['model_score'] = pipeline_df_llama3['model_score'].astype(int)\n",
    "pipeline_df_llama3['preferred_answer'] = pipeline_df_llama3['preferred_answer'].astype(int)\n",
    "pipeline_df_llama3['model_res_number'] = pipeline_df_llama3['model_res_number'].astype(int)\n",
    "\n",
    "pipeline_df_llama3.to_csv(\"../../evals/human/pairwise-comparison/results/pipeline_llama3_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get values of interest from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages (0=gpt3.5, 1=gpt4, 2=llama3)\n",
      "   human_score  model_score\n",
      "0     0.400000     0.600000\n",
      "1     0.333333     0.666667\n",
      "2     0.250000     0.750000\n"
     ]
    }
   ],
   "source": [
    "pipeline_gpt35_results = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt3_5_results.csv\")\n",
    "pipeline_gpt4_results = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt4_results.csv\")\n",
    "pipeline_llama3_results = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_llama3_results.csv\")\n",
    "\n",
    "pipeline_gpt35_average = pipeline_gpt35_results.groupby('source_file')[['model_score']].mean()\n",
    "pipeline_gpt4_average = pipeline_gpt4_results.groupby('source_file')[['model_score']].mean()\n",
    "pipeline_llama3_average = pipeline_llama3_results.groupby('source_file')[['model_score']].mean()\n",
    "\n",
    "results_df = pd.concat([pipeline_gpt35_average, pipeline_gpt4_average, pipeline_llama3_average], axis=0, ignore_index=True)\n",
    "results_df[\"human_score\"] = 1.0 - results_df[\"model_score\"]\n",
    "\n",
    "# Specify the new column order\n",
    "new_column_order = ['human_score', 'model_score']\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "results_df = results_df[new_column_order]\n",
    "\n",
    "print(\"Averages (0=gpt3.5, 1=gpt4, 2=llama3)\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute krippendorffs alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred Answer Array:\n",
      "[[1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/wpldr7zj16g6s0l2mb0tl3f00000gn/T/ipykernel_34255/165693786.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pivot_preferred_answer = pivot_preferred_answer.applymap(lambda x: np.nan if pd.isnull(x) else x)\n"
     ]
    }
   ],
   "source": [
    "import krippendorff\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for the Krippendorf calculation\n",
    "df1 = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt3_5_results.csv\")\n",
    "df2 = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_gpt4_results.csv\")\n",
    "df3 = pd.read_csv(\"../../evals/human/pairwise-comparison/results/pipeline_llama3_results.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "\n",
    "# Create three pivot tables, one for each metric (the aggfunc is only used to deal with duplicate question_number-respondent pairs)\n",
    "pivot_preferred_answer = df.pivot_table(index='respondent', columns='question_number', values='preferred_answer', aggfunc='mean')\n",
    "\n",
    "# Replace missing values with np.nan\n",
    "pivot_preferred_answer = pivot_preferred_answer.applymap(lambda x: np.nan if pd.isnull(x) else x)\n",
    "\n",
    "# Convert pivot tables to numpy arrays\n",
    "array_preferred_answer = pivot_preferred_answer.to_numpy()\n",
    "\n",
    "\n",
    "verbose = True\n",
    "if verbose:\n",
    "    # Print the arrays to check\n",
    "    print(\"Preferred Answer Array:\")\n",
    "    print(array_preferred_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.453125\n"
     ]
    }
   ],
   "source": [
    "# Calculate Krippendorff's alpha for each question\n",
    "alpha_preferred_answer = krippendorff.alpha(reliability_data=array_preferred_answer, level_of_measurement=\"ordinal\")\n",
    "\n",
    "print(alpha_preferred_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
